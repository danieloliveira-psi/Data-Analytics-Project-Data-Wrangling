# Project: Data Wrangling

## Introduction

This is the fourth project I had to complete for the Data Analytics Nanodegree on Udacity.
For this project, I had to get data related to a twitter page and perform data wrangling activities.

## Main Goal

This project aims at performing all necessary data wrangling activities in order to be able to analyse data from the twitter page: [@dog_rates](https://twitter.com/dog_rates), also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog.
The goal of the project was to perform the following tasks:

- Step 1: Gathering data
- Step 2: Assessing data
- Step 3: Cleaning data
- Step 4: Storing data
- Step 5: Analyzing, and visualizing data (basic analysis, because the focus was on data wrangling)
- Step 6: Reporting (2 html files, which are added here)



## What was used

With Anaconda's help, it was used python 3.x, and jupyter.
Regarding packages, it was used pandas, numpy, requests, tweepy (twitter API), json, time and matplotlib (inline).
The following data sources were used:
- csv file with twitter archive data given from the @dog_rates
- tsv file with predictions regarding the photo of the dog, which we were able to get using the requests package
- txt file with twitter data directly from Twitter (using Tweepy, with all key data as undisclosed in this file, putting all json data on this txt file)

## Other

Please, don't copy this project to conclude similar Udacity (or other platforms) courses. I hope, however, that it can help you with some insights.